#One Stock predictor Involved, however others exist and can help with more accurate prediction
#Create an AI + ML Pipeline Workflow
#Finviz allows to pull finance data without paid subscription and stock data from yFinance
#LLM Classification (Ollama - Open source Meta Llama 3)
#Create Positive and Neg Artiticle Headlines
#Finally Create Time Series Model using ARIMAX (Autoregressive Integrated Moving Average) or FBProphet
#WebAPP run on Streamlit.io
#Will need to create Local LLM Server Connection from LangChain Community to import Ollama


### Libraries & Ollama ###


#pip install yfinance, finvizfinance, statsmodels, plotly, holidays, langchain-community, streamlit, Ollama
#in terminal, run 'ollama run llama3', will install meta llam3 on latop

import yfinance as yf                                   #gather stock data
from finvizfinance.quote import finvizfinance           #gather recent stock news article headlines
from statsmodels.tsa.statespace.sarimax import SARIMAX  #SARIMAX Data Modelling Library, to predict time series forecast
import plotly.graph_objects as go                       #modelling charts
import pandas as pd                                     #pandas for finance packages and data manipulation
import numpy as np
import holidays                                         #to avoid forecasting on holidays
from langchain_community.llms import Ollama             #create local LLM server connection
import streamlit as st                                  #for interactive Web App UI
llm = Ollama(model='llama3')                            #connect to local Ollama server using Ollama call function, will be using llama3 version


### Sentiment Model Functions ###


def sentiment_classifier(title):                                              #function allows to ollama to classify titles as pos, neg, or neu; strip removes any extra spaces
    sentiment_output = llm.invoke(f"Classify the sentiment as 'POSITIVE' or 'NEGATIVE' or 'NEUTRAL' with just that one only, no additional words or reasoning: {title}")
    return sentiment_output.strip()

def news_data(ticker):                                                        #function gathers and process news headlines
    stock = finvizfinance(ticker)
    stknews_df = stock.ticker_news()                                          #pulls data into news dataframe

    stknews_df['Title'] = stknews_df['Title'].str.lower()                     #lowercases title headlines for preprocessing
    stknews_df['sentiment'] = stknews_df['Title'].apply(sentiment_classifier) #applies the classify_sentiment function to each title in the 'Title' column and stores the result in a new 'sentiment' column

    stknews_df['sentiment'] = stknews_df['sentiment'].str.upper()             #uppercases sentiment df
    stknews_df = stknews_df[stknews_df['sentiment'] != 'NEUTRAL']             #removes any sentiment that returns NEUTRAL, as they are not useful
    stknews_df['Date'] = pd.to_datetime(stknews_df['Date'])                   #Pandas function converts the 'Date' column to datetime format for easier date manipulation
    stknews_df['DateOnly'] = stknews_df['Date'].dt.date                       #creates a new 'DateOnly' column that contains only the date part of the datetime, excluding the time

    return stknews_df

def sentiment_data_processor(stknews_df):
    grp_stknews_df = stknews_df.groupby(['DateOnly', 'sentiment']).size().unstack(fill_value=0)                             #groups the data by date and sentiment, count occurrences, and unstacks the result
    grp_stknews_df = grp_stknews_df.reindex(columns=['POSITIVE', 'NEGATIVE'], fill_value=0)                                 #'POSITIVE' and 'NEGATIVE' columns exist and empty columns fill with 0 if missing

    grp_stknews_df['7DAY_AVG_POS'] = grp_stknews_df['POSITIVE'].rolling(window=7, min_periods=1).sum()                      #calc 7-day rolling sum for pos sentiments
    grp_stknews_df['7DAY_AVG_NEG'] = grp_stknews_df['NEGATIVE'].rolling(window=7, min_periods=1).sum()                      #7-day rolling sum for neg sentiments

    grp_stknews_df['7DAY_POS_PCT'] = grp_stknews_df['POSITIVE'] / (grp_stknews_df['POSITIVE'] + grp_stknews_df['NEGATIVE']) #calc the % of pos sentiments for each day
    final_grp_stknews_df = grp_stknews_df.reset_index()                                                                     #reset the index to make 'DateOnly' a column instead of an index
    
    return final_grp_stknews_df

def get_stock_data(ticker, start_date, end_date):
    stock_data = yf.download(ticker, start=start_date, end=end_date)  
    stock_data['Pct_Change'] = stock_data['Close'].pct_change() * 100 
    return stock_data

#def combine_data(result_df, stock_data):
    # Combine and rename columns using concatenation
    combined_df = pd.concat([
        result_df.set_index('DateOnly')[['7day_pct_positive']].rename(
            columns={'7day_pct_positive': '7Day Positive'}),
        stock_data.set_index('DateOnly')[['Pct_Change']].rename(  # Ensure stock_data has DateOnly index
            columns={'Pct_Change': 'Historical Daily Change'})
    ], axis=1, join='inner').reset_index()  # Keep DateOnly as column for clarity
    
    # Create lagged feature with descriptive name
    combined_df['Previous Day 7Day Positive'] = combined_df['7Day Positive'].shift(1)
    return combined_df

#def combine_data(result_df, stock_data):
    combined_df = result_df.set_index('DateOnly').join(stock_data[['Pct_Change']], how='inner')
    combined_df['lagged_7day_pct_positive'] = combined_df['7day_pct_positive'].shift(1)
    return combined_df


def combine_data(result_df, stock_data):
    # Ensure both DataFrames have matching single-level indices
    result_indexed = result_df.set_index('DateOnly')
    stock_indexed = stock_data.reset_index().set_index('DateOnly')  # Flatten potential MultiIndex
    
    # Combine using concat with inner join
    combined_df = pd.concat([
        result_indexed[['7day_pct_positive']].rename(
            columns={'7day_pct_positive': '7Day Positive'}),
        stock_indexed[['Pct_Change']].rename(
            columns={'Pct_Change': 'Historical Daily Change'})
    ], axis=1, join='inner')

    # Create lagged feature with clear naming
    combined_df['Previous Day 7Day Positive'] = combined_df['7Day Positive'].shift(1)
    
    return combined_df.reset_index()  # Return DateOnly as column for readability

def calculate_correlation(combined_df):
    correlation_pct_change = combined_df[['lagged_7day_pct_positive', 'Pct_Change']].corr().iloc[0, 1]
    return correlation_pct_change

def get_future_dates(start_date, num_days):
    us_holidays = holidays.US()
    future_dates = []
    current_date = start_date
    while len(future_dates) < num_days:
        if current_date.weekday() < 5 and current_date not in us_holidays:
            future_dates.append(current_date)
        current_date += pd.Timedelta(days=1)
    return future_dates

def fit_and_forecast(combined_df, forecast_steps=3):
    endog = combined_df['Pct_Change'].dropna()  
    exog = combined_df['lagged_7day_pct_positive'].dropna()  
    endog = endog.loc[exog.index]  
    model = SARIMAX(endog, exog=exog, order=(1, 1, 1))  
    fit = model.fit(disp=False)  
    
    future_dates = get_future_dates(combined_df.index[-1], forecast_steps)  
    future_exog = combined_df['lagged_7day_pct_positive'][-forecast_steps:].values.reshape(-1, 1)
    
    forecast = fit.get_forecast(steps=forecast_steps, exog=future_exog)  
    forecast_mean = forecast.predicted_mean  
    forecast_ci = forecast.conf_int()  
    
    return forecast_mean, forecast_ci, future_dates  


def create_plot(combined_df, forecast_mean, forecast_ci, forecast_index):
    
    sentiment_std = (combined_df['7day_pct_positive'] - combined_df['7day_pct_positive'].mean()) / combined_df['7day_pct_positive'].std()

    fig = go.Figure()
    
    
    fig.add_trace(go.Scatter(
        x=combined_df.index, 
        y=sentiment_std, 
        name='Standardized Sentiment Proportion', 
        line=dict(color='blue'), 
        mode='lines'
    ))
    
    
    fig.add_trace(go.Scatter(
        x=combined_df.index, 
        y=combined_df['Pct_Change'], 
        name='Stock Pct Change', 
        line=dict(color='green'), 
        yaxis='y2', 
        mode='lines'
    ))
    
    
    fig.add_trace(go.Scatter(
        x=forecast_index, 
        y=forecast_mean, 
        name='Forecasted Pct Change', 
        line=dict(color='red'), 
        mode='lines'
    ))
    
    
    fig.add_trace(go.Scatter(
        x=np.concatenate([forecast_index, forecast_index[::-1]]),
        y=np.concatenate([forecast_ci.iloc[:, 0], forecast_ci.iloc[:, 1][::-1]]),
        fill='toself',
        fillcolor='rgba(255,0,0,0.2)',
        line=dict(color='rgba(255,255,255,0)'),
        hoverinfo="skip",
        showlegend=False
    ))
    
    
    fig.update_layout(
        title='Sentiment Proportion and Stock Percentage Change with Forecast',
        xaxis_title='Date',
        yaxis=dict(
            title='Standardized Sentiment Proportion',
            titlefont=dict(color='blue')
        ),
        yaxis2=dict(
            title='Stock Pct Change',
            titlefont=dict(color='green'),
            overlaying='y',
            side='right'
        ),
        template='plotly_dark'
    )
    st.plotly_chart(fig)

st.sidebar.title("Predicting Stock Prices by News Sentiment")
ticker = st.sidebar.text_input("Enter stock ticker (e.g., SBUX):", value='SBUX')
run_button = st.sidebar.button("Run Analysis")

if run_button:
    news_df = news_data(ticker)
    result_df = sentiment_data_processor(news_df)
    start_date = result_df['DateOnly'].min().strftime('%Y-%m-%d')
    end_date = result_df['DateOnly'].max().strftime('%Y-%m-%d')
    stock_data = get_stock_data(ticker, start_date, end_date)
    combined_df = combine_data(result_df, stock_data)
    correlation_pct_change = calculate_correlation(combined_df)
    st.write(f'Pearson correlation between lagged sentiment score and stock percentage change: {correlation_pct_change}')
    forecast_mean, forecast_ci, forecast_index = fit_and_forecast(combined_df)
    create_plot(combined_df, forecast_mean, forecast_ci, forecast_index)
